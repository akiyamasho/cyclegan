{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('cyclegan')\n",
    "\n",
    "!pip install -r requirements_dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import cv2\n",
    "import logging\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from PIL import Image\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "RANDOM_FILENAME_LENGTH = 12\n",
    "\n",
    "# Folder names\n",
    "ROOT_DATASET_FOLDER = \"datasets\"\n",
    "DATASET_NAME = \"threeD2twoD\"\n",
    "A_3D_VIDEO_FILE = \"A_3D_256.mp4\"\n",
    "B_2D_VIDEO_FILE = \"B_2D_256.mp4\"\n",
    "\n",
    "A_3D_OUTPUT_FOLDER = \"A_3D_256_frames\"\n",
    "B_2D_OUTPUT_FOLDER = \"B_2D_256_frames\"\n",
    "\n",
    "# Paths\n",
    "A_3D_VIDEO_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, A_3D_VIDEO_FILE)\n",
    "A_3D_RAW_DATASET_PATH = os.path.join(\n",
    "    ROOT_DATASET_FOLDER, DATASET_NAME, A_3D_OUTPUT_FOLDER\n",
    ")\n",
    "\n",
    "B_2D_VIDEO_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, B_2D_VIDEO_FILE)\n",
    "B_2D_RAW_DATASET_PATH = os.path.join(\n",
    "    ROOT_DATASET_FOLDER, DATASET_NAME, B_2D_OUTPUT_FOLDER\n",
    ")\n",
    "\n",
    "OUTPUT_IMAGE_EXT = \".png\"\n",
    "\n",
    "SHOULD_RANDOMISE_FILENAMES = False # Set this to True to shuffle the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(\n",
    "    input_file_path: str,\n",
    "    output_folder_path: str,\n",
    "    should_randomise: bool = SHOULD_RANDOMISE_FILENAMES,\n",
    "):\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.mkdir(output_folder_path)\n",
    "\n",
    "    vidcap = cv2.VideoCapture(input_file_path)\n",
    "    frame_count = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    logger.info(f\"Extracting {frame_count} frames from `{input_file_path}`\")\n",
    "    _, image = vidcap.read()\n",
    "    count = 0\n",
    "\n",
    "    for count in tqdm_notebook(range(frame_count)):\n",
    "        raw_frame_file_name = (\n",
    "            f\"{hashlib.sha1(os.urandom(32)).hexdigest()[:RANDOM_FILENAME_LENGTH]}{OUTPUT_IMAGE_EXT}\"\n",
    "            if should_randomise\n",
    "            else f\"{count:03d}{OUTPUT_IMAGE_EXT}\"\n",
    "        )\n",
    "        frame_file_path = os.path.join(output_folder_path, raw_frame_file_name)\n",
    "        cv2.imwrite(frame_file_path, image)\n",
    "        _, image = vidcap.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames(input_file_path=A_3D_VIDEO_PATH, output_folder_path=A_3D_RAW_DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dup_cmd = f\"image-cleaner {A_3D_RAW_DATASET_PATH}\"\n",
    "!{remove_dup_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_frames(input_file_path=B_2D_VIDEO_PATH, output_folder_path=B_2D_RAW_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dup_cmd = f\"image-cleaner {B_2D_RAW_DATASET_PATH}\"\n",
    "!{remove_dup_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CycleGAN Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split Config\n",
    "\n",
    "TRAIN_SPLIT = 0.9\n",
    "TEST_SPLIT = 1 - TRAIN_SPLIT\n",
    "\n",
    "TRAIN_A_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, \"trainA\")\n",
    "TRAIN_B_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, \"trainB\")\n",
    "TEST_A_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, \"testA\")\n",
    "TEST_B_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, \"testB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(raw_dataset_path: str, train_path: str, test_path: str):\n",
    "    files = os.listdir(raw_dataset_path)\n",
    "    total_file_count = len(files)\n",
    "    logger.info(f\"Found total de-duplicated {total_file_count} images.\")\n",
    "\n",
    "    if not os.path.exists(train_path):\n",
    "        os.mkdir(train_path)\n",
    "    \n",
    "    if not os.path.exists(test_path):\n",
    "        os.mkdir(test_path)\n",
    "\n",
    "    # Train\n",
    "    no_of_files = math.floor(total_file_count * TRAIN_SPLIT)\n",
    "    logger.info(f\"Moving {no_of_files} files to training set...\")\n",
    "    for file_name in tqdm_notebook(random.sample(files, no_of_files)):\n",
    "        shutil.move(os.path.join(raw_dataset_path, file_name), train_path)\n",
    "\n",
    "    # Test\n",
    "    remaining_files = os.listdir(raw_dataset_path)\n",
    "    logger.info(f\"Moving {len(remaining_files)} files to test set...\")\n",
    "    for file_name in tqdm_notebook(remaining_files):\n",
    "        shutil.move(os.path.join(raw_dataset_path, file_name), test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_test(raw_dataset_path=A_3D_RAW_DATASET_PATH, train_path=TRAIN_A_PATH, test_path=TEST_A_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_test(raw_dataset_path=B_2D_RAW_DATASET_PATH, train_path=TRAIN_B_PATH, test_path=TEST_B_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pix2Pix Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test/Val Split Config\n",
    "# This assumes A to B\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "TEST_SPLIT = 0.1\n",
    "VAL_SPLIT = 1 - (TRAIN_SPLIT + TEST_SPLIT)\n",
    "\n",
    "SIDEBYSIDE_IMAGE_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, \"sidebyside\")\n",
    "\n",
    "TRAIN_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, \"test\")\n",
    "TEST_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, \"train\")\n",
    "VAL_PATH = os.path.join(ROOT_DATASET_FOLDER, DATASET_NAME, \"val\")\n",
    "\n",
    "IMAGE_DIMENSION = 256\n",
    "MERGED_WIDTH = IMAGE_DIMENSION * 2\n",
    "CHANNELS = \"RGB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_images(image_A: Image.Image, image_B: Image.Image) -> Image.Image:\n",
    "    merged_image = Image.new(CHANNELS, (MERGED_WIDTH, IMAGE_DIMENSION))\n",
    "    \n",
    "    merged_image.paste(image_A, (0,0))\n",
    "    merged_image.paste(image_B, (IMAGE_DIMENSION,0))\n",
    "\n",
    "    return merged_image\n",
    "\n",
    "def merge_frames(folder_A_path: str, folder_B_path: str, output_folder_path: str):\n",
    "    file_names = os.listdir(folder_A_path)\n",
    "\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.mkdir(output_folder_path)\n",
    "\n",
    "    for file_name in tqdm_notebook(file_names):\n",
    "        image_A_path = os.path.join(folder_A_path, file_name)\n",
    "        image_B_path = os.path.join(folder_B_path, file_name)\n",
    "        image_A = Image.open(image_A_path)\n",
    "        image_B = Image.open(image_B_path)\n",
    "\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "        merged_image = merge_two_images(image_A, image_B)\n",
    "        merged_image_output_path = os.path.join(output_folder_path, base_name.zfill(len(str(len(file_names)))) + \".png\")\n",
    "\n",
    "        merged_image.save(merged_image_output_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_val(raw_dataset_path: str, train_path: str, test_path: str, val_path: str):\n",
    "    files = os.listdir(raw_dataset_path)\n",
    "    total_file_count = len(files)\n",
    "    logger.info(f\"Found total de-duplicated {total_file_count} images.\")\n",
    "\n",
    "    if not os.path.exists(train_path):\n",
    "        os.mkdir(train_path)\n",
    "    \n",
    "    if not os.path.exists(test_path):\n",
    "        os.mkdir(test_path)\n",
    "\n",
    "    if not os.path.exists(val_path):\n",
    "        os.mkdir(val_path)\n",
    "\n",
    "    # Train\n",
    "    no_of_files = math.floor(total_file_count * TRAIN_SPLIT)\n",
    "    logger.info(f\"Moving {no_of_files} files to training set...\")\n",
    "    for file_name in tqdm_notebook(random.sample(files, no_of_files)):\n",
    "        shutil.move(os.path.join(raw_dataset_path, file_name), train_path)\n",
    "\n",
    "    # Test\n",
    "    files = os.listdir(raw_dataset_path)\n",
    "    no_of_files = math.floor(total_file_count * TEST_SPLIT)\n",
    "    logger.info(f\"Moving {no_of_files} files to test set...\")\n",
    "    for file_name in tqdm_notebook(random.sample(files, no_of_files)):\n",
    "        shutil.move(os.path.join(raw_dataset_path, file_name), test_path)\n",
    "\n",
    "    # Val\n",
    "    remaining_files = os.listdir(raw_dataset_path)\n",
    "    logger.info(f\"Moving {len(remaining_files)} files to validation set...\")\n",
    "    print(val_path)\n",
    "    for file_name in tqdm_notebook(remaining_files):\n",
    "        shutil.move(os.path.join(raw_dataset_path, file_name), val_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_frames(folder_A_path=A_3D_RAW_DATASET_PATH, folder_B_path=B_2D_RAW_DATASET_PATH, output_folder_path=SIDEBYSIDE_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_dup_cmd = f\"image-cleaner {SIDEBYSIDE_IMAGE_PATH}\"\n",
    "!{remove_dup_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_test_val(raw_dataset_path=SIDEBYSIDE_IMAGE_PATH, train_path=TRAIN_PATH, test_path=TEST_PATH, val_path=VAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
